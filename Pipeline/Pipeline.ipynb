{"cells": [{"metadata": {}, "cell_type": "code", "source": "!pip install tweepy\n!pip install demoji\n!pip install preprocessor\n!pip install unidecode\n!pip install -U spacy==3.0.6\n!python3 -m spacy download en_core_web_md\n!pip install ibm_watson", "execution_count": 133, "outputs": [{"output_type": "stream", "text": "Requirement already satisfied: tweepy in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (4.2.0)\nRequirement already satisfied: requests-oauthlib<2,>=1.0.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tweepy) (1.3.0)\nRequirement already satisfied: requests<3,>=2.11.1 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tweepy) (2.25.1)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests<3,>=2.11.1->tweepy) (2.8)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests<3,>=2.11.1->tweepy) (3.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests<3,>=2.11.1->tweepy) (2021.10.8)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests<3,>=2.11.1->tweepy) (1.26.6)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests-oauthlib<2,>=1.0.0->tweepy) (3.1.1)\nRequirement already satisfied: demoji in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (1.1.0)\nRequirement already satisfied: preprocessor in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (1.1.3)\nRequirement already satisfied: unidecode in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (1.3.2)\nRequirement already satisfied: spacy==3.0.6 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (3.0.6)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from spacy==3.0.6) (2.0.6)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from spacy==3.0.6) (2.25.1)\nRequirement already satisfied: thinc<8.1.0,>=8.0.3 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from spacy==3.0.6) (8.0.12)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.4 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from spacy==3.0.6) (3.0.8)\nRequirement already satisfied: pathy>=0.3.5 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from spacy==3.0.6) (0.6.1)\nRequirement already satisfied: pydantic<1.8.0,>=1.7.1 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from spacy==3.0.6) (1.7.4)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from spacy==3.0.6) (3.0.6)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from spacy==3.0.6) (4.59.0)\nRequirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from spacy==3.0.6) (0.7.5)\nRequirement already satisfied: jinja2 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from spacy==3.0.6) (3.0.0)\nRequirement already satisfied: setuptools in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from spacy==3.0.6) (52.0.0.post20211006)\nRequirement already satisfied: wasabi<1.1.0,>=0.8.1 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from spacy==3.0.6) (0.8.2)\nRequirement already satisfied: srsly<3.0.0,>=2.4.1 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from spacy==3.0.6) (2.4.2)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.3 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from spacy==3.0.6) (2.0.6)\nRequirement already satisfied: numpy>=1.15.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from spacy==3.0.6) (1.19.2)\nRequirement already satisfied: typer<0.4.0,>=0.3.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from spacy==3.0.6) (0.3.2)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from spacy==3.0.6) (1.0.6)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from spacy==3.0.6) (20.9)\nRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from packaging>=20.0->spacy==3.0.6) (2.4.7)\nRequirement already satisfied: smart-open<6.0.0,>=5.0.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from pathy>=0.3.5->spacy==3.0.6) (5.1.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy==3.0.6) (2021.10.8)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy==3.0.6) (1.26.6)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy==3.0.6) (3.0.4)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy==3.0.6) (2.8)\nRequirement already satisfied: click<7.2.0,>=7.1.1 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from typer<0.4.0,>=0.3.0->spacy==3.0.6) (7.1.2)\nRequirement already satisfied: MarkupSafe>=2.0.0rc2 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from jinja2->spacy==3.0.6) (2.0.1)\nCollecting en-core-web-md==3.0.0\n  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.0.0/en_core_web_md-3.0.0-py3-none-any.whl (47.1 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 47.1 MB 24.6 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: spacy<3.1.0,>=3.0.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from en-core-web-md==3.0.0) (3.0.6)\nRequirement already satisfied: typer<0.4.0,>=0.3.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (0.3.2)\nRequirement already satisfied: numpy>=1.15.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (1.19.2)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (3.0.6)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (4.59.0)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.4 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (3.0.8)\nRequirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (0.7.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (1.0.6)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (20.9)\nRequirement already satisfied: pathy>=0.3.5 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (0.6.1)\nRequirement already satisfied: setuptools in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (52.0.0.post20211006)\nRequirement already satisfied: srsly<3.0.0,>=2.4.1 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (2.4.2)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (2.25.1)\nRequirement already satisfied: jinja2 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (3.0.0)\nRequirement already satisfied: wasabi<1.1.0,>=0.8.1 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (0.8.2)\nRequirement already satisfied: pydantic<1.8.0,>=1.7.1 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (1.7.4)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (2.0.6)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.3 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (2.0.6)\nRequirement already satisfied: thinc<8.1.0,>=8.0.3 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (8.0.12)\n", "name": "stdout"}, {"output_type": "stream", "text": "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (2.4.7)\nRequirement already satisfied: smart-open<6.0.0,>=5.0.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from pathy>=0.3.5->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (5.1.0)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (2.8)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (1.26.6)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (2021.10.8)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (3.0.4)\nRequirement already satisfied: click<7.2.0,>=7.1.1 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (7.1.2)\nRequirement already satisfied: MarkupSafe>=2.0.0rc2 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from jinja2->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (2.0.1)\n\u001b[38;5;2m\u2714 Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('en_core_web_md')\nRequirement already satisfied: ibm_watson in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (5.3.0)\nRequirement already satisfied: python-dateutil>=2.5.3 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from ibm_watson) (2.8.1)\nRequirement already satisfied: websocket-client==1.1.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from ibm_watson) (1.1.0)\nRequirement already satisfied: requests<3.0,>=2.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from ibm_watson) (2.25.1)\nRequirement already satisfied: ibm-cloud-sdk-core==3.*,>=3.3.6 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from ibm_watson) (3.10.1)\nRequirement already satisfied: PyJWT<3.0.0,>=2.0.1 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from ibm-cloud-sdk-core==3.*,>=3.3.6->ibm_watson) (2.1.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from python-dateutil>=2.5.3->ibm_watson) (1.15.0)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests<3.0,>=2.0->ibm_watson) (3.0.4)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests<3.0,>=2.0->ibm_watson) (2.8)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests<3.0,>=2.0->ibm_watson) (2021.10.8)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests<3.0,>=2.0->ibm_watson) (1.26.6)\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "import sys\nimport urllib3, requests, json\n#import boto3 \nimport pandas as pd\n##Librer\u00edas para guardar en ICOS\nfrom ibm_botocore.client import Config\nimport ibm_boto3", "execution_count": 134, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Import data from WA"}, {"metadata": {}, "cell_type": "code", "source": "#Cargando credenciales\n##credentials de ICOS\ncredentials = {\n    'IBM_API_KEY_ID': 'N6s71csGj-oQkR6Rq5uPzK387nyDrOWiA0pf297sFOAX',\n    'IAM_SERVICE_ID': 'crn:v1:bluemix:public:iam-identity::a/fff9f38d90d4668d4cb41cda4b360333::serviceid:ServiceId-2f51bf37-2f1e-4114-8479-471eb0985c0d',\n    'ENDPOINT': 'https://s3.us-south.cloud-object-storage.appdomain.cloud',\n    'IBM_AUTH_ENDPOINT': 'https://iam.bluemix.net/oidc/token',\n    'BUCKET': 'wave-ai-hackatonai'\n    }\n\ncos = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id=credentials['IBM_API_KEY_ID'],\n    ibm_service_instance_id=credentials['IAM_SERVICE_ID'],\n    ibm_auth_endpoint=credentials['IBM_AUTH_ENDPOINT'],\n    config=Config(signature_version='oauth'),\n    endpoint_url=credentials['ENDPOINT'])\n\n#Descargando el file inicial\ncos.download_file(Bucket=credentials['BUCKET'],Key='students_information.csv',Filename='students_information.csv')\ncos.download_file(Bucket=credentials['BUCKET'],Key='students_information_emotional.csv',Filename='students_information_emotional.csv')", "execution_count": 211, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "tabla_ini = pd.read_csv('students_information.csv')\ntabla_fin = pd.read_csv('students_information_emotional.csv')", "execution_count": 212, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "registro_ini = pd.DataFrame(tabla_ini.iloc[-1]).transpose()\nregistro_ini", "execution_count": 213, "outputs": [{"output_type": "execute_result", "execution_count": 213, "data": {"text/plain": "  Unnamed: 0 AGE ANSWER_PROBLEM FEELINGS HOURS_SLEEP   NAME PROBLEM1  \\\n8          8  18     No matters    Upset          15  Julio    False   \n\n  PROBLEM_TYPE QUALITY WHERE_PROBLEM  \n8         None    True          None  ", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>AGE</th>\n      <th>ANSWER_PROBLEM</th>\n      <th>FEELINGS</th>\n      <th>HOURS_SLEEP</th>\n      <th>NAME</th>\n      <th>PROBLEM1</th>\n      <th>PROBLEM_TYPE</th>\n      <th>QUALITY</th>\n      <th>WHERE_PROBLEM</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>18</td>\n      <td>No matters</td>\n      <td>Upset</td>\n      <td>15</td>\n      <td>Julio</td>\n      <td>False</td>\n      <td>None</td>\n      <td>True</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Parte Kevin"}, {"metadata": {}, "cell_type": "code", "source": "import demoji\ndemoji.download_codes()", "execution_count": 214, "outputs": [{"output_type": "stream", "text": "<ipython-input-214-eb011a9810ad>:2: FutureWarning: The demoji.download_codes attribute is deprecated and will be removed from demoji in a future version. It is an unused attribute as emoji codes are now distributed directly with the demoji package.\n  demoji.download_codes()\n", "name": "stderr"}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Importing libraries"}, {"metadata": {}, "cell_type": "code", "source": "#Importing Libraries\nimport preprocessor as p\nimport pandas as pd\nimport re\nimport demoji\nimport unicodedata\nimport string\nimport numpy as np\nimport pandas as pd\nimport string as s\nimport unidecode\na=string.punctuation\nimport pickle\nfrom ibm_botocore.client import Config\nimport ibm_boto3\nimport pandas as pd\nimport gensim # Gensim general  for LDA\nimport gensim.corpora as corpora\nimport spacy\nfrom spacy.tokens import Token, Doc\nfrom spacy.language import Language\nfrom spacy.lang.en.stop_words import STOP_WORDS", "execution_count": 215, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Preprocessing text "}, {"metadata": {}, "cell_type": "code", "source": "def remove_urls(row): \n    text=row['text']\n    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n    a=url_pattern.sub(r'', text)\n    return a\ndef demojir(row):\n    text=row['text']\n    text=demoji.replace(text)\n    return text\ndef remove_user(row):\n    text=row['text']\n    r = re.findall(\"@[\\w]*\", text)\n    for i in r:\n        text = re.sub(i, '', text)\n    return text\ndef remove_hastag(row):\n    text=row['text']\n    r = re.findall(\"#[\\w]*\", text)\n    for i in r:\n        text = re.sub(i, '', text)\n    return text\ndef remove_rt(row):\n    text=row['text']\n    r = re.findall('RT :', text)\n    for i in r:\n        text = re.sub(i, '', text)\ndef signos(row):\n\n    sentences=row['text']\n    text_string=re.findall('[\\w]+',sentences)\n    cad=' '.join(text_string)\n    cad=unidecode.unidecode(cad)\n    cad2=cad.translate(str.maketrans(\"\",'',a))\n    cad3=cad2.split()\n    cad4=' '.join(cad3)\n    \n    return cad4", "execution_count": 216, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#registro['ANSWER_PROBLEM'] = data.apply(demojir, axis=1)\n#registro['ANSWER_PROBLEM'] = data.apply(remove_user, axis=1)\n#registro['ANSWER_PROBLEM'] = data.apply(remove_hastag, axis=1)\n#registro['ANSWER_PROBLEM'] = data.apply(remove_rt, axis=1)\n#registro['ANSWER_PROBLEM'] = data.apply(remove_urls, axis=1)\n#registro['ANSWER_PROBLEM'] = data.apply(signos, axis=1)\n#registro['FEELINGS'] = data.apply(demojir, axis=1)\n#registro['FEELINGS'] = data.apply(remove_user, axis=1)\n#registro['FEELINGS'] = data.apply(remove_hastag, axis=1)\n#registro['FEELINGS'] = data.apply(remove_rt, axis=1)\n#registro['FEELINGS'] = data.apply(remove_urls, axis=1)\n#registro['FEELINGS'] = data.apply(signos, axis=1)", "execution_count": 217, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "text = registro.iloc[0][2] + \" \" + registro.iloc[0][3]\ntext", "execution_count": 218, "outputs": [{"output_type": "execute_result", "execution_count": 218, "data": {"text/plain": "'No matters Upset'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "# SENTIMENT ANALYSIS "}, {"metadata": {}, "cell_type": "code", "source": "import json\nfrom ibm_watson import NaturalLanguageUnderstandingV1\nfrom ibm_watson.natural_language_understanding_v1 import Features, EntitiesOptions, KeywordsOptions, SentimentOptions, RelationsOptions\nfrom ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n\nfrom ibm_cloud_sdk_core.authenticators import IAMAuthenticator\nfrom ibm_watson.natural_language_understanding_v1 import Features, EmotionOptions\n\nimport pandas as pd\nimport numpy as np\n\nfrom ibm_watson import ToneAnalyzerV3\nfrom ibm_cloud_sdk_core.authenticators import IAMAuthenticator", "execution_count": 219, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#Authentication via IAM\nauthenticator = IAMAuthenticator('yrGJ1qfuxZA9SWOfV-DTUH6XKr0ywbOzvWQRIqeri3EE')\nservice = NaturalLanguageUnderstandingV1(\n    version='2019-07-12',\n    authenticator=authenticator)\nservice.set_service_url('https://api.eu-de.natural-language-understanding.watson.cloud.ibm.com/instances/82ba706b-4934-49bf-b6c0-8c11df7d4a12')", "execution_count": 220, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "response = service.analyze(\n            text=text,\n            features=Features(sentiment=SentimentOptions(),\n                              keywords=KeywordsOptions())).get_result()\nlabel_sentiment = response['sentiment']['document']['label']", "execution_count": 221, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# EMOTION CLASSIFICATION "}, {"metadata": {}, "cell_type": "code", "source": "#Authentication via IAM - Tone Analyzer\n\nauthenticator = IAMAuthenticator('y9HmBnI8hEd9Dq6ii_Idbs7bz9C63_qmSlqat5w5HlEF')\ntone_analyzer = ToneAnalyzerV3(\n    version='2017-09-21',\n    authenticator=authenticator\n)\ntone_analyzer.set_service_url('https://api.au-syd.tone-analyzer.watson.cloud.ibm.com/instances/6eb005c7-a6b8-45e1-b45d-26e1cb4b3809')", "execution_count": 222, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "tone_analysis = tone_analyzer.tone({'text': text},content_type='application/json').get_result()\ncont = 0\nif len(tone_analysis['document_tone']['tones']) != 0:\n    for i in tone_analysis['document_tone']['tones']:\n        if cont == 0:\n            score = str(i['score'])\n            tone = str(i['tone_name'])\n            cont += 1\n        else:\n            score = str(score) + ',' + str(i['score'])\n            tone = str(tone) + ',' + str(i['tone_name'])\n            cont += 1   \nelse:\n    tone = 'None'\nlabel_tone = tone", "execution_count": 223, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# TOPIC MODELING -LDA\n"}, {"metadata": {}, "cell_type": "markdown", "source": "## LDA must-preprocessing steps"}, {"metadata": {}, "cell_type": "code", "source": "#Remove no textual characters\ndef regex_spacy(text):\n    #Realizar antes de tokenizar porque spacy tokeniza mal algunas palabras con este inconveniente\n    #new_text = re.sub(r'0001[Ff]\\d+|0001[Ff]\\d[Ff][Ff]',' ', text).strip()\n   # new_text = re.sub(r'0001[Ff]\\d+[a-zA-Z]',' ', new_text).strip()\n    new_text = re.sub(r'0001[a-zA-Z]\\d+[a-zA-Z]|0001[a-zA-Z]\\d+|0001[a-zA-Z]\\d[a-zA-Z][a-zA-Z]',' ', text).strip()\n    new_text = re.sub(r'06[a-z][a-z]|06\\d[a-z]',' ', new_text).strip()\n    if new_text==\"\":\n        return ' '\n    else:\n        return new_text", "execution_count": 224, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "@Language.component(\"preproc_doc\")\n# Define the function that takes a doc and performs most of the cleaning and remove stop_words\ndef preproc_doc(doc):\n    preproc_doc=[]\n    spacesD=[]\n    for token in doc:\n        if token.is_punct==False and token.like_num==False and token.is_digit==False and token.is_space==False and token.is_currency==False and token.like_url==False and not token.is_stop and token.text != '-PRON-' and len(token.text)>2:\n            preproc_doc.append(token.text)\n            spacesD.append(True)\n    \n    if preproc_doc==[]:\n        return Doc(doc.vocab, words=[\"No_words\"],spaces=[False])\n    else:\n        ##output a Doc spacy object\n        spacesD[-1]=False\n        #print(lemma_doc,\"\\n\",spacesD)\n        return Doc(doc.vocab, words=preproc_doc,spaces=spacesD)\n", "execution_count": 225, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "@Language.component(\"lemmatizer_doc\")\n# Define the function that takes a doc and performs lemmatization it\ndef lemmatizer_doc(doc):\n    lemma_doc=[]\n    spacesD=[]\n    for token in doc:\n        lemma_doc.append(token.lemma_)\n        spacesD.append(True)\n    \n    ##output a Doc spacy object\n    spacesD[-1]=False\n    #print(lemma_doc,\"\\n\",spacesD)\n    return Doc(doc.vocab, words=lemma_doc,spaces=spacesD)", "execution_count": 226, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "@Language.component(\"replace_words_doc\")\n# Define the function that takes a doc and replace some specific words, like contractions or abbreviations\ndef replace_words_doc(doc):\n    replace_doc=[]\n    spacesD=[]\n    for token in doc:\n        #detectar si es una palabra a reemplazar\n        if token.text in dictionary_words.keys():\n            n_word=dictionary_words[token.text].split()\n            replace_doc.extend(n_word)\n        else:\n            replace_doc.append(token.text)\n    \n    for i in range(len(replace_doc)):\n        spacesD.append(True)\n        \n    ##output a Doc spacy object\n    spacesD[-1]=False\n    #print(lemma_doc,\"\\n\",spacesD)\n    return Doc(doc.vocab, words=replace_doc,spaces=spacesD)", "execution_count": 227, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "def all_text_data_preproc(dataset):\n    '''\n    Main function to perform preprocessing\n    '''\n    clean_data=dataset.apply(regex_spacy)\n    news_doc=nlp.pipe(clean_data.to_numpy())\n    print(\"Pipeline Done\")\n\n    data=list(pd.Series([docs.text for docs in news_doc],name=\"Text_clean\",dtype='object',index=dataset.index))\n\n    return pd.DataFrame(data, columns=['text'])\n", "execution_count": 228, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "nlp = spacy.load('en_core_web_md', disable=[\"parser\",\"ner\"])  #\"ner\",\nnlp.add_pipe('replace_words_doc', first=True)\nnlp.add_pipe('lemmatizer_doc', last=True)\nnlp.add_pipe('preproc_doc', last=True)", "execution_count": 229, "outputs": [{"output_type": "execute_result", "execution_count": 229, "data": {"text/plain": "<function __main__.preproc_doc(doc)>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Replacing words lists "}, {"metadata": {}, "cell_type": "code", "source": "dictionary_words={'anxious':'anxiety', 'stresseda':'stressed', 'don':\"do not\", 'dona':\"do not\", 'didn':\"did not\", \"anxiousa\":\"anxiety\"}\n## D.C. de washington dc\ndictionary_words", "execution_count": 230, "outputs": [{"output_type": "execute_result", "execution_count": 230, "data": {"text/plain": "{'anxious': 'anxiety',\n 'stresseda': 'stressed',\n 'don': 'do not',\n 'dona': 'do not',\n 'didn': 'did not',\n 'anxiousa': 'anxiety'}"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "##  Customized stopwords"}, {"metadata": {}, "cell_type": "code", "source": "customize_stop_words = [\n    'ita', 'people', 'amp','lac','fe0f','200d', 'hello', 'ripley'\n]\n#'064a','062a','062f', 'blanket', 'thena', 'ripley', 'push', 'know', 'hello', 'time', 'think'\nfor w in customize_stop_words:\n    nlp.vocab[w].is_stop = True\n", "execution_count": 231, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Loading the dictionary"}, {"metadata": {}, "cell_type": "code", "source": "cos.download_file(Bucket=credentials['BUCKET'],Key='ModelVF_7topics.id2word',\n                  Filename='ModelVF_7topics.id2word')\nlda_dictionary=corpora.Dictionary.load('ModelVF_7topics.id2word')", "execution_count": 232, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Loading the model"}, {"metadata": {}, "cell_type": "code", "source": "cos.download_file(Bucket=credentials['BUCKET'],Key='ModelVF_7topics.expElogbeta.npy',\n                  Filename='ModelVF_7topics.expElogbeta.npy')\ncos.download_file(Bucket=credentials['BUCKET'],Key='ModelVF_7topics.state',\n                  Filename='ModelVF_7topics.state')", "execution_count": 233, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "cos.download_file(Bucket=credentials['BUCKET'],Key='ModelVF_7topics',\n                  Filename='ModelVF_7topics')\nlda_model=gensim.models.ldamulticore.LdaMulticore.load('ModelVF_7topics')", "execution_count": 234, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "def format_topics_keywords(dataset,modelo_lda, termFreq):\n    ''' Function to add the dominat topic per doc and its perc contribution'''\n    frame=pd.DataFrame()\n    ##get dominant_topic\n    frame[\"Dominant_Topic\"]=termFreq.apply(lambda y: sorted(modelo_lda.get_document_topics(y), key=lambda x: (x[1]), reverse=True)[0][0]+1)##+1 para que no haya el topic 0\n    #print(\"D_topic\\n\",frame[['Dominant_Topic']].head())\n    ##add its perc_contribution\n    frame['Perc_Contribution']=termFreq.apply(lambda y: round(sorted(modelo_lda.get_document_topics(y), key=lambda x: (x[1]), reverse=True)[0][1],4))\n    #print(\"P_topic\")\n    ##add key words per dominant_topic\n    Topics_Keywords=pd.DataFrame({'Dominant_Topic':frame['Dominant_Topic'].unique()})\n    #print(Topics_Keywords)\n    Topics_Keywords['Topic_Keywords']=Topics_Keywords['Dominant_Topic'].apply(lambda x: \", \".join([word for word, prop in modelo_lda.show_topic(x-1)]))\n    ##Labeling topics\n    Topics_Keywords[\"Label_Topic\"] = Topics_Keywords[\"Dominant_Topic\"].map({1: \"Home Conflicts/Bullying\",\n                                                                           2: \"Depression/Anxiety\",\n                                                                           3: \"Bullying\",\n                                                                           4: \"Mental Health/Anxiety\",\n                                                                           5: \"Depression/Bullying\",\n                                                                           6: \"Sadness/Depression/Anxiety\",\n                                                                           7: \"College anxiety/ Dropout\"\n                                                                          })\n    frame=pd.merge(frame,Topics_Keywords, on=\"Dominant_Topic\", how=\"inner\").sort_index()\n    #data.join(Topics_Keywords, on=\"Dominant_Topic\", how=\"inner\", rsuffix='_other')\n    return pd.concat([dataset,frame], axis=1)", "execution_count": 235, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "data= [text]", "execution_count": 236, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "dummy_data=pd.DataFrame(data, columns=['text'])\ndummy_data=all_text_data_preproc(dummy_data['text'])\ndata_clean_tokens=dummy_data['text'].apply(lambda x: str(x).split(' '))\n# Term Document Frequency - BOW\nbow = data_clean_tokens.apply(lambda x: lda_dictionary.doc2bow(x))", "execution_count": 237, "outputs": [{"output_type": "stream", "text": "Pipeline Done\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "data=format_topics_keywords(dummy_data,lda_model, bow)\ndata", "execution_count": 238, "outputs": [{"output_type": "execute_result", "execution_count": 238, "data": {"text/plain": "           text  Dominant_Topic  Perc_Contribution  \\\n0  matter Upset               7             0.5697   \n\n                                      Topic_Keywords               Label_Topic  \n0  human, dropout, anxiety, college, time, calm, ...  College anxiety/ Dropout  ", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>Dominant_Topic</th>\n      <th>Perc_Contribution</th>\n      <th>Topic_Keywords</th>\n      <th>Label_Topic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>matter Upset</td>\n      <td>7</td>\n      <td>0.5697</td>\n      <td>human, dropout, anxiety, college, time, calm, ...</td>\n      <td>College anxiety/ Dropout</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "lista = registro.iloc[-1].tolist()\nlista.pop(0)\nlista2 = data.iloc[-1].tolist()\nlista.extend(lista2)\nlista.append(label_sentiment)\nlista.append(label_tone)", "execution_count": 239, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "data_final = pd.DataFrame(lista).transpose()\n# adding column name to the respective columns\ndata_final.columns = ['AGE','ANSWER_PROBLEM','FEELINGS','HOURS_SLEEP','NAME','PROBLEM1','PROBLEM_TYPE','QUALITY',\n                      'WHERE_PROBLEM','text','Dominant_Topic','Perc_Contribution','Topic_Keywords','Label_Topic','SENTIMENT','EMOTION']\ndata_final", "execution_count": 240, "outputs": [{"output_type": "execute_result", "execution_count": 240, "data": {"text/plain": "  AGE ANSWER_PROBLEM FEELINGS HOURS_SLEEP   NAME PROBLEM1 PROBLEM_TYPE  \\\n0  18     No matters    Upset          15  Julio    False         None   \n\n  QUALITY WHERE_PROBLEM          text Dominant_Topic Perc_Contribution  \\\n0    True          None  matter Upset              7            0.5697   \n\n                                      Topic_Keywords  \\\n0  human, dropout, anxiety, college, time, calm, ...   \n\n                Label_Topic SENTIMENT EMOTION  \n0  College anxiety/ Dropout   neutral    None  ", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AGE</th>\n      <th>ANSWER_PROBLEM</th>\n      <th>FEELINGS</th>\n      <th>HOURS_SLEEP</th>\n      <th>NAME</th>\n      <th>PROBLEM1</th>\n      <th>PROBLEM_TYPE</th>\n      <th>QUALITY</th>\n      <th>WHERE_PROBLEM</th>\n      <th>text</th>\n      <th>Dominant_Topic</th>\n      <th>Perc_Contribution</th>\n      <th>Topic_Keywords</th>\n      <th>Label_Topic</th>\n      <th>SENTIMENT</th>\n      <th>EMOTION</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>18</td>\n      <td>No matters</td>\n      <td>Upset</td>\n      <td>15</td>\n      <td>Julio</td>\n      <td>False</td>\n      <td>None</td>\n      <td>True</td>\n      <td>None</td>\n      <td>matter Upset</td>\n      <td>7</td>\n      <td>0.5697</td>\n      <td>human, dropout, anxiety, college, time, calm, ...</td>\n      <td>College anxiety/ Dropout</td>\n      <td>neutral</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "tabla_fin = tabla_fin.drop(columns=['Unnamed: 0'])", "execution_count": 241, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "tabla_fin = tabla_fin.append(data_final)\ntabla_fin.tail()", "execution_count": 242, "outputs": [{"output_type": "execute_result", "execution_count": 242, "data": {"text/plain": "  AGE                   ANSWER_PROBLEM  FEELINGS HOURS_SLEEP   NAME PROBLEM1  \\\n6  15  mis padres perdieron el trabajo  very bad           5    vir      yes   \n7  15  mis padres perdieron el trabajo  very bad           5    vir      yes   \n8  18                       No matters     Upset          15  Julio    FALSE   \n9  18                       No matters     Upset          15  Julio    False   \n0  18                       No matters     Upset          15  Julio    False   \n\n  PROBLEM_TYPE    QUALITY WHERE_PROBLEM  \\\n6    financial  dont have       at home   \n7    financial  dont have       at home   \n8         None       TRUE          None   \n9         None       True          None   \n0         None       True          None   \n\n                                       text Dominant_Topic Perc_Contribution  \\\n6  mis padres perdieron el trabajo very bad              7            0.5697   \n7  mis padres perdieron el trabajo very bad              7            0.5697   \n8                          No matters Upset              7            0.5697   \n9                              matter Upset              7            0.5697   \n0                              matter Upset              7            0.5697   \n\n                                      Topic_Keywords  \\\n6             human, dropout, anxiety, college, time   \n7             human, dropout, anxiety, college, time   \n8             human, dropout, anxiety, college, time   \n9  human, dropout, anxiety, college, time, calm, ...   \n0  human, dropout, anxiety, college, time, calm, ...   \n\n                Label_Topic SENTIMENT  EMOTION  \n6  College anxiety/ Dropout  Negative  Sadness  \n7  College anxiety/ Dropout  Negative  Sadness  \n8  College anxiety/ Dropout  Negative  Sadness  \n9  College anxiety/ Dropout   neutral     None  \n0  College anxiety/ Dropout   neutral     None  ", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AGE</th>\n      <th>ANSWER_PROBLEM</th>\n      <th>FEELINGS</th>\n      <th>HOURS_SLEEP</th>\n      <th>NAME</th>\n      <th>PROBLEM1</th>\n      <th>PROBLEM_TYPE</th>\n      <th>QUALITY</th>\n      <th>WHERE_PROBLEM</th>\n      <th>text</th>\n      <th>Dominant_Topic</th>\n      <th>Perc_Contribution</th>\n      <th>Topic_Keywords</th>\n      <th>Label_Topic</th>\n      <th>SENTIMENT</th>\n      <th>EMOTION</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6</th>\n      <td>15</td>\n      <td>mis padres perdieron el trabajo</td>\n      <td>very bad</td>\n      <td>5</td>\n      <td>vir</td>\n      <td>yes</td>\n      <td>financial</td>\n      <td>dont have</td>\n      <td>at home</td>\n      <td>mis padres perdieron el trabajo very bad</td>\n      <td>7</td>\n      <td>0.5697</td>\n      <td>human, dropout, anxiety, college, time</td>\n      <td>College anxiety/ Dropout</td>\n      <td>Negative</td>\n      <td>Sadness</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>15</td>\n      <td>mis padres perdieron el trabajo</td>\n      <td>very bad</td>\n      <td>5</td>\n      <td>vir</td>\n      <td>yes</td>\n      <td>financial</td>\n      <td>dont have</td>\n      <td>at home</td>\n      <td>mis padres perdieron el trabajo very bad</td>\n      <td>7</td>\n      <td>0.5697</td>\n      <td>human, dropout, anxiety, college, time</td>\n      <td>College anxiety/ Dropout</td>\n      <td>Negative</td>\n      <td>Sadness</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>18</td>\n      <td>No matters</td>\n      <td>Upset</td>\n      <td>15</td>\n      <td>Julio</td>\n      <td>FALSE</td>\n      <td>None</td>\n      <td>TRUE</td>\n      <td>None</td>\n      <td>No matters Upset</td>\n      <td>7</td>\n      <td>0.5697</td>\n      <td>human, dropout, anxiety, college, time</td>\n      <td>College anxiety/ Dropout</td>\n      <td>Negative</td>\n      <td>Sadness</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>18</td>\n      <td>No matters</td>\n      <td>Upset</td>\n      <td>15</td>\n      <td>Julio</td>\n      <td>False</td>\n      <td>None</td>\n      <td>True</td>\n      <td>None</td>\n      <td>matter Upset</td>\n      <td>7</td>\n      <td>0.5697</td>\n      <td>human, dropout, anxiety, college, time, calm, ...</td>\n      <td>College anxiety/ Dropout</td>\n      <td>neutral</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>18</td>\n      <td>No matters</td>\n      <td>Upset</td>\n      <td>15</td>\n      <td>Julio</td>\n      <td>False</td>\n      <td>None</td>\n      <td>True</td>\n      <td>None</td>\n      <td>matter Upset</td>\n      <td>7</td>\n      <td>0.5697</td>\n      <td>human, dropout, anxiety, college, time, calm, ...</td>\n      <td>College anxiety/ Dropout</td>\n      <td>neutral</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "## Saving in ICOS\ntabla_fin.to_csv('students_information_emotional.csv')\ncos.upload_file(Filename='students_information_emotional.csv',Bucket=credentials['BUCKET'],Key='students_information_emotional.csv')", "execution_count": 243, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Convert csv in json"}, {"metadata": {}, "cell_type": "code", "source": "import csv \nimport json \n\ndef csv_to_json(csvFilePath, jsonFilePath):\n    jsonArray = []\n      \n    #read csv file\n    with open(csvFilePath, encoding='utf-8') as csvf: \n        #load csv file data using csv library's dictionary reader\n        csvReader = csv.DictReader(csvf) \n\n        #convert each csv row into python dict\n        for row in csvReader: \n            #add this python dict to json array\n            jsonArray.append(row)\n  \n    #convert python jsonArray to JSON String and write to file\n    with open(jsonFilePath, 'w', encoding='utf-8') as jsonf: \n        jsonString = json.dumps(jsonArray, indent=4)\n        jsonf.write(jsonString)\n          \ncsvFilePath = r'students_information_emotional.csv'\njsonFilePath = r'students_information_emotional.json'\ncsv_to_json(csvFilePath, jsonFilePath)", "execution_count": 244, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "ls", "execution_count": 245, "outputs": [{"output_type": "stream", "text": "ModelVF_7topics                  students_information.csv\r\nModelVF_7topics.expElogbeta.npy  students_information_emotional.csv\r\nModelVF_7topics.id2word          students_information_emotional.json\r\nModelVF_7topics.state\r\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Saving in Github"}, {"metadata": {}, "cell_type": "code", "source": "import requests \nimport base64\n\ntoken = \"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\"\n\nrepo = 'virginiamonroy/wave_ai'\npath = 'students_information_emotional.json'\n\ndata = open(\"students_information_emotional.json\", \"r\").read()\n\nr = requests.put(\n    f'https://api.github.com/repos/{repo}/contents/{path}',\n    headers = {\n        'Authorization': f'Token {token}'\n    },\n    json = {\n        \"message\": \"add new file\",\n        \"content\": base64.b64encode(data.encode()).decode()\n    }\n)\n#print(r.status_code)\n#print(r.json())", "execution_count": 246, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.8", "language": "python"}, "language_info": {"name": "python", "version": "3.8.11", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}